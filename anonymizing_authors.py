# -*- coding: utf-8 -*-
"""anonymizing_authors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16DMTAXVynXhnxqnF6T9gu36KYEQhTFi4
"""

pip install PyPDF4

pip install scrubadub

import re
import PyPDF4

with open('/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf','rb') as f:
  pdf_reader = PyPDF4.PdfFileReader(f)
  pdf_wirter = PyPDF4.PdfFileWriter()

  for page_num in range(pdf_reader.getNumPages()):
    page = pdf_reader.getPage(page_num)
    text = page.extractText()

print(text)

author_names = re.findall(r'([A-Z][a-z]*\s[A-Z][a-z]*)', text)
for i, author_name in enumerate(author_names):
            author_regex = re.compile(re.escape(author_name), re.IGNORECASE)
            text = author_regex.sub(f'Author {i+1}', text)

affiliations = re.findall(r'([A-Z][a-z]*\s[A-Z][a-z]*\s?[A-Z]?[a-z]*)', text)
for i, affiliation in enumerate(affiliations):
            affiliation_regex = re.compile(re.escape(affiliation), re.IGNORECASE)
            text = affiliation_regex.sub(f'Affiliation {i+1}', text)

funding_sources = re.findall(r'((F|f)unded by.+)', text)
for i, funding_source in enumerate(funding_sources):
            funding_regex = re.compile(re.escape(funding_source), re.IGNORECASE)
            text = funding_regex.sub(f'Funding source {i+1}', text)

import PyPDF4
import scrubadub
import io

# Open the research paper PDF and create a new PDF writer
with open('/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf', 'rb') as f:
    pdf_reader = PyPDF4.PdfFileReader(f)
    pdf_writer = PyPDF4.PdfFileWriter()

    # Loop through each page of the PDF
    for page_num in range(pdf_reader.getNumPages()):
        page = pdf_reader.getPage(page_num)
        text = page.extractText()

        # Anonymize author names using scrubadub
        anonymized_text = scrubadub.clean(text)

        # Add the anonymized page to the PDF writer
        #page = pdf_writer.addBlankPage(page.mediaBox.getWidth(), page.mediaBox.getHeight())
        #page.mergePage(PyPDF4.pdf.PageObject.createFromString(anonymized_text))
        bytes_io = io.BytesIO(text.encode('utf-8'))
        #temp_reader = PyPDF4.PdfFileReader(bytes_io)
        #temp_page = temp_reader.getPage(0)
        #pdf_writer.addPage(temp_page)

    # Write the anonymized research paper PDF to a new file
    with open('anonymized_research_paper.pdf', 'wb') as f:
        pdf_writer.write(f)

print(f)

!pip install anonympy

pip install cape_privacy

import anonympy

anonympy.__version__

from anonympy.pdf import pdfAnonymizer

!pip install tesseract

!sudo apt install tesseract-ocr
!pip install pytesseract

import pytesseract
import shutil
import os
import random
try:
 from PIL import Image
except ImportError:
 import Image

anonym = pdfAnonymizer(path_to_pdf = '/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf')

!apt-get install poppler-utils

import PyPDF4
import re

# Open the PDF file
pdf_file = open('/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf','r')
# Read the PDF file
pdf_reader = PyPDF4.PdfFileReader(open('/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf','rb'))

# Get the total number of pages
num_pages = pdf_reader.getNumPages()

# Regular expression pattern to match author
anon_pattern = r"^\[\d+\]"

# Loop through each page
for page in range(num_pages):
    # Get the text of the current page
    page_text = pdf_reader.getPage(page).extractText()

    # Split the text into lines
    lines = page_text.split('\n')

    # Loop through each line
    for line in lines:
        # Check if the line matches the reference pattern
        if re.match(anon_pattern, line):
            print("Anonymous author found:", line)

# Close the PDF file
pdf_file.close()

import PyPDF4
import spacy

# Step 1: Extract text from PDF file
pdf_file = open('/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf', 'rb')
pdf_reader = PyPDF4.PdfFileReader(pdf_file)

text = ""
for page_num in range(pdf_reader.numPages):
    page = pdf_reader.getPage(page_num)
    text += page.extractText()

#print(page)
#print(text)


# Step 2: Load NER model and identify entities in text
nlp = spacy.load('en_core_web_sm')
doc = nlp(text)

# Step 3: Replace identified entities with anonymous labels
anon_text = ""
anon_map = {}
for ent in doc.ents:
    if ent.label_ == 'PERSON':
        # Generate anonymous label
        anon_label = f'[ANON_{len(anon_map)}]'
        anon_map[ent.text] = anon_label

        

# Step 4: Print anonymized text and mapping of original names to anonymous labels
print(anon_text)
print(anon_map)
print()

pip install regex

import PyPDF4

pdf_file = open('/content/Heart_Disease_Prediction_using_Hybrid_machine_Learning_Model.pdf', 'rb')
pdf_reader = PyPDF4.PdfFileReader(pdf_file)

text = ''
for page_num in range(pdf_reader.getNumPages()):
    page = pdf_reader.getPage(page_num)
    text += page.extractText()

print(text)

author_input = str(input("Enter the author names (separated by commas): "))
authors = [author.strip() for author in author_input.split(',')]

import re

author_pattern = r"\b(" + '|'.join([re.escape(author) for author in authors]) + r")\b"

text = str(text)

text_anon = re.sub(author_pattern, 'Anonymous', text)

with open('research_paper_anon.pdf', 'w') as f:
    f.write(text_anon)

print(f)